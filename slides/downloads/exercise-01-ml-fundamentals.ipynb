{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 - Building a Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to load in our dataset. We will be using the `spotifyclassification` (available [here](https://www.kaggle.com/datasets/geomack/spotifyclassification)) for this exercise.\n",
    "\n",
    "Use the \"Add Input\" button in the panel on the right to make these datasets available to your notebook. If you have successfully added these datasets, then running the cell below should print the path you can use to load them in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-07T01:44:47.709811Z",
     "iopub.status.busy": "2024-12-07T01:44:47.708702Z",
     "iopub.status.idle": "2024-12-07T01:44:47.718466Z",
     "shell.execute_reply": "2024-12-07T01:44:47.717248Z",
     "shell.execute_reply.started": "2024-12-07T01:44:47.709760Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below imports some packages that we will use for building and evaluating our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T01:44:47.720924Z",
     "iopub.status.busy": "2024-12-07T01:44:47.720558Z",
     "iopub.status.idle": "2024-12-07T01:44:47.732492Z",
     "shell.execute_reply": "2024-12-07T01:44:47.731335Z",
     "shell.execute_reply.started": "2024-12-07T01:44:47.720893Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we're ready to get started. Let's load in our first dataset and take a look at it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T01:44:47.736196Z",
     "iopub.status.busy": "2024-12-07T01:44:47.735722Z",
     "iopub.status.idle": "2024-12-07T01:44:47.772834Z",
     "shell.execute_reply": "2024-12-07T01:44:47.771655Z",
     "shell.execute_reply.started": "2024-12-07T01:44:47.736148Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "spotify_df = pd.read_csv(\"/kaggle/input/spotifyclassification/data.csv\", index_col=0)\n",
    "spotify_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains a number of features of songs from 2017 available on Spotify, and a binary variable `target` that represents whether the user liked the song (encoded as 1) or not (encoded as 0).\n",
    "\n",
    "These are *one* user's listening preferences. We will investigate whether the features Spotify provides are helpful in predicting whether or not a user likes a particular song."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Questions: \n",
    "1. Look up the documentation of the features [here](https://developer.spotify.com/documentation/web-api/reference/get-audio-features). Which ones do you think are likely to help with predicting our **target** column? Which ones are best discarded?\n",
    "\n",
    "2. Is this is supervised, unsupervised or self-supervised machine learning problem? Do we want to perform inference or prediction?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, our first task should be to split our data into a training and test set. We will not access the test data until the very end, when we are ready to evaluate our final trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T01:44:47.775021Z",
     "iopub.status.busy": "2024-12-07T01:44:47.774645Z",
     "iopub.status.idle": "2024-12-07T01:44:47.782057Z",
     "shell.execute_reply": "2024-12-07T01:44:47.780845Z",
     "shell.execute_reply.started": "2024-12-07T01:44:47.774988Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split the data\n",
    "\n",
    "train_df, test_df = train_test_split(spotify_df, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check how many data points our training and test sets contain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T01:44:47.784068Z",
     "iopub.status.busy": "2024-12-07T01:44:47.783711Z",
     "iopub.status.idle": "2024-12-07T01:44:47.802097Z",
     "shell.execute_reply": "2024-12-07T01:44:47.800769Z",
     "shell.execute_reply.started": "2024-12-07T01:44:47.784032Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "n_train_samples = train_df.shape[0]\n",
    "n_test_samples = test_df.shape[0]\n",
    "\n",
    "print(f\"Training Examples: {n_train_samples}\")\n",
    "print(f\"Test Examples: {n_test_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas also allows us to conveniently calculate some summary statistics for our dataset. For example, we can check what the mean and standard deviation for our numerical columns is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T01:44:47.804107Z",
     "iopub.status.busy": "2024-12-07T01:44:47.803727Z",
     "iopub.status.idle": "2024-12-07T01:44:47.857748Z",
     "shell.execute_reply": "2024-12-07T01:44:47.856624Z",
     "shell.execute_reply.started": "2024-12-07T01:44:47.804076Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "\n",
    "spotify_summary = train_df.describe()\n",
    "spotify_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first try to understand our dataset by examining some features directly. The code below produces histograms for the `loudness` feature using pandas plotting. The histograms show the distribution of the feature values in the training set, separated for positive (target=1, i.e., user liked the song) and negative (target=0, i.e., user disliked the song) examples.\n",
    "\n",
    "There are two different histograms, one for target = 0 and one for target = 1, and they are overlaid on top of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T01:44:47.862259Z",
     "iopub.status.busy": "2024-12-07T01:44:47.861426Z",
     "iopub.status.idle": "2024-12-07T01:44:48.403202Z",
     "shell.execute_reply": "2024-12-07T01:44:48.402004Z",
     "shell.execute_reply.started": "2024-12-07T01:44:47.862207Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plotting the loudness feature\n",
    "\n",
    "feat = \"loudness\"\n",
    "train_df.groupby(\"target\")[feat].plot.hist(bins=50, alpha=0.5, legend=True, density = True, title = \"Histogram of \" + feat);\n",
    "plt.xlabel(feat);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram shows that extremely quiet songs tend to be disliked (more blue bars than orange on the left) and very loud songs also tend to be disliked (more blue than orange on the far right)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question:\n",
    "\n",
    "Suppose we were to build a decision tree using only the `loudness` feature. What would a good decision tree look like? What threshold values is our model likely to learn? How deep should we make our tree?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More plotting\n",
    "\n",
    "The code below makes similar plots for some other features-- specifically `acousticness`, `danceability`, `tempo`, `energy` and `valence`. Run the cell and examine the histograms generated. Feel free to include more features in the list to be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T01:44:48.404958Z",
     "iopub.status.busy": "2024-12-07T01:44:48.404577Z",
     "iopub.status.idle": "2024-12-07T01:44:50.658372Z",
     "shell.execute_reply": "2024-12-07T01:44:50.657283Z",
     "shell.execute_reply.started": "2024-12-07T01:44:48.404922Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"acousticness\",\n",
    "    \"danceability\",\n",
    "    \"tempo\",\n",
    "    \"energy\",\n",
    "    \"valence\",\n",
    "]\n",
    "for feat in features:\n",
    "    ax = train_df.groupby(\"target\")[feat].plot.hist(bins=50, alpha=0.5, legend=True, density = True, title=\"Histogram of \" + feat)\n",
    "    plt.xlabel(feat)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question:\n",
    "\n",
    "Some features (like `tempo`) seem to have a similar distribution between both target classes (0 and 1). Should we drop these features from our data, based onthe histograms we plotted?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to drop `song_title` and `artist` since they are text features. (Do you expect either feature to be useful?)\n",
    "\n",
    "We are also separating the features from the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T01:44:50.660214Z",
     "iopub.status.busy": "2024-12-07T01:44:50.659877Z",
     "iopub.status.idle": "2024-12-07T01:44:50.667292Z",
     "shell.execute_reply": "2024-12-07T01:44:50.666229Z",
     "shell.execute_reply.started": "2024-12-07T01:44:50.660183Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=[\"target\", \"song_title\", \"artist\"])\n",
    "y_train = train_df[\"target\"]\n",
    "\n",
    "X_test = test_df.drop(columns=[\"target\", \"song_title\", \"artist\"])\n",
    "y_test = test_df[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Classifier\n",
    "\n",
    "First, we train a dummy classifier. This gives us a baseline prediction against which to compare our model performance.\n",
    "\n",
    "The dummy classifier predicts the same value of the target for all examples in the training set. When we call `fit()`, our dummy classifier learns the most common value of the target. The function `score()` then predicts this value for all examples, and returns the proportion which were correctly predicted. So the value returned here is the proportion of examples that belong to the most common target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T01:44:50.669290Z",
     "iopub.status.busy": "2024-12-07T01:44:50.668870Z",
     "iopub.status.idle": "2024-12-07T01:44:50.693940Z",
     "shell.execute_reply": "2024-12-07T01:44:50.692708Z",
     "shell.execute_reply.started": "2024-12-07T01:44:50.669245Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dummy Classifier\n",
    "\n",
    "dummy = DummyClassifier(random_state=123)\n",
    "dummy.fit(X_train, y_train)\n",
    "dummy.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a balanced dataset! We have a close to 50-50 split between the target classes. Any ML model that actually learned useful information should perform with an accuracy higher than 50%.\n",
    "\n",
    "We are now ready to build our decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T01:44:50.696057Z",
     "iopub.status.busy": "2024-12-07T01:44:50.695543Z",
     "iopub.status.idle": "2024-12-07T01:44:50.704109Z",
     "shell.execute_reply": "2024-12-07T01:44:50.703017Z",
     "shell.execute_reply.started": "2024-12-07T01:44:50.695999Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Creating a decision tree\n",
    "\n",
    "spotify_tree = DecisionTreeClassifier(random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train and score our tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T01:44:50.705896Z",
     "iopub.status.busy": "2024-12-07T01:44:50.705394Z",
     "iopub.status.idle": "2024-12-07T01:44:50.749441Z",
     "shell.execute_reply": "2024-12-07T01:44:50.748368Z",
     "shell.execute_reply.started": "2024-12-07T01:44:50.705770Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "spotify_tree.fit(X_train, y_train)\n",
    "spotify_tree.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That score is *very* high. Our model is classifying training examples with near-perfect accuracy! \n",
    "\n",
    "---\n",
    "#### Question:\n",
    "\n",
    "Do we trust our training scores to give a good prediction for model performance on unseen data? Have we built a good model?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how deep the fitted decision tree looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T01:44:50.751307Z",
     "iopub.status.busy": "2024-12-07T01:44:50.750972Z",
     "iopub.status.idle": "2024-12-07T01:44:50.757687Z",
     "shell.execute_reply": "2024-12-07T01:44:50.756594Z",
     "shell.execute_reply.started": "2024-12-07T01:44:50.751277Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "spotify_tree.get_depth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Question:\n",
    "\n",
    "You should see a decision tree of depth 17. How many distinct training examples could a depth 17 decision tree memorize? How many examples exist in our dataset?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be good to know what features our tree thought were important! Let's visualize the first few nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T01:44:50.759282Z",
     "iopub.status.busy": "2024-12-07T01:44:50.758976Z",
     "iopub.status.idle": "2024-12-07T01:44:50.783156Z",
     "shell.execute_reply": "2024-12-07T01:44:50.782138Z",
     "shell.execute_reply.started": "2024-12-07T01:44:50.759254Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training with just depth 3\n",
    "\n",
    "three_model = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "three_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T01:44:50.785394Z",
     "iopub.status.busy": "2024-12-07T01:44:50.784572Z",
     "iopub.status.idle": "2024-12-07T01:44:51.391286Z",
     "shell.execute_reply": "2024-12-07T01:44:51.389964Z",
     "shell.execute_reply.started": "2024-12-07T01:44:50.785347Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plotting\n",
    "\n",
    "plot_tree(three_model, filled=True, \n",
    "               feature_names = X_train.columns.to_list(),\n",
    "               impurity = False,\n",
    "               fontsize = 7,\n",
    "               label = None);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### Question:\n",
    "\n",
    "What features do you see the tree using? Do they match the features you expected to see based on the histograms in your EDA?\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model achieved a near-perfect training score. However, since we trained on all data in our training set, we have not yet been able to measure model performance on new, unseen data.\n",
    "\n",
    "Let's check how well our trained model does on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T01:44:51.394942Z",
     "iopub.status.busy": "2024-12-07T01:44:51.394542Z",
     "iopub.status.idle": "2024-12-07T01:44:51.405648Z",
     "shell.execute_reply": "2024-12-07T01:44:51.404333Z",
     "shell.execute_reply.started": "2024-12-07T01:44:51.394908Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "spotify_tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm. That wasn't nearly as good. We went from perfect predictions on training data to only 68% accuracy on test data. It is likely that we have overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding a better model\n",
    "\n",
    "We fit a very deep decision tree that likely just memorized our dataset. A shallower tree might limit some of the overfitting, so let's try forcing a maximum depth on our tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T01:44:51.408072Z",
     "iopub.status.busy": "2024-12-07T01:44:51.407268Z",
     "iopub.status.idle": "2024-12-07T01:44:51.416694Z",
     "shell.execute_reply": "2024-12-07T01:44:51.415457Z",
     "shell.execute_reply.started": "2024-12-07T01:44:51.408023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_model = DecisionTreeClassifier(max_depth=5, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train and score this model as usual on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T01:44:51.418569Z",
     "iopub.status.busy": "2024-12-07T01:44:51.418207Z",
     "iopub.status.idle": "2024-12-07T01:44:51.445992Z",
     "shell.execute_reply": "2024-12-07T01:44:51.444887Z",
     "shell.execute_reply.started": "2024-12-07T01:44:51.418520Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_model.fit(X_train, y_train)\n",
    "new_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a lower training score than before. But what about test score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T01:44:51.448256Z",
     "iopub.status.busy": "2024-12-07T01:44:51.447484Z",
     "iopub.status.idle": "2024-12-07T01:44:51.458896Z",
     "shell.execute_reply": "2024-12-07T01:44:51.457814Z",
     "shell.execute_reply.started": "2024-12-07T01:44:51.448208Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's still some overfitting, but we're getting a better test score than what we got before (with a deeper, more complex decision tree!) Also, there is less of a gap between our training and test scores, so our model is generalizating reasonably to new data, and making sensible predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hold on... did we violate the Golden Rule?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used our test set twice, which means we violated the Golden Rule of Machine Learning. In practice, it is *not* a good idea to use our test set multiple times with different models. The more often we use it, the less certain we can be of our model's predictions out in the real world. We might start overfitting to test data, even though we don't use it to directly update model parameters.\n",
    "\n",
    "This is a real danger, and can lead us to picking bad models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Question:\n",
    "\n",
    "If re-using the test set is bad, but we cannot evaluate model performance until we measure it on unseen data, how are we to select good values for hyperparameters or choose between models?\n",
    "\n",
    "How do we find the best `max_depth` for modelling our Spotify data?\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning is generally carried out using **cross-validation**. Essentially, this involves setting aside part of your training data as a 'validation set' to be used *only* for testing (and not for fitting each individual model). Then, validation accuracy can be used as a proxy for test accuracy.\n",
    "\n",
    "Sklearn has many helper functions to make cross-validation easy (see [here](https://scikit-learn.org/1.5/modules/cross_validation.html#cross-validation-and-model-selection))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "Sklearn also has a built-in function to tell you which features the decision tree *thinks* are most important for making predictions (based on its learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T01:55:07.401797Z",
     "iopub.status.busy": "2024-12-07T01:55:07.400647Z",
     "iopub.status.idle": "2024-12-07T01:55:07.408157Z",
     "shell.execute_reply": "2024-12-07T01:55:07.406895Z",
     "shell.execute_reply.started": "2024-12-07T01:55:07.401752Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "impt = new_model.feature_importances_\n",
    "for i, f in enumerate(X_train.columns.to_list()):\n",
    "    print(f\"{f}: \", round(impt[i], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Food for thought... (Bonus Question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below takes the \"index\" column of this dataset and allows us to use it as a feature. What might be the result of using the index as a feature for this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T01:44:51.460637Z",
     "iopub.status.busy": "2024-12-07T01:44:51.460312Z",
     "iopub.status.idle": "2024-12-07T01:44:51.472222Z",
     "shell.execute_reply": "2024-12-07T01:44:51.470975Z",
     "shell.execute_reply.started": "2024-12-07T01:44:51.460606Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train_2 = X_train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T01:44:51.473991Z",
     "iopub.status.busy": "2024-12-07T01:44:51.473539Z",
     "iopub.status.idle": "2024-12-07T01:44:51.492913Z",
     "shell.execute_reply": "2024-12-07T01:44:51.491648Z",
     "shell.execute_reply.started": "2024-12-07T01:44:51.473957Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "index_model = DecisionTreeClassifier(random_state=123)\n",
    "index_model.fit(X_train_2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T01:44:51.495423Z",
     "iopub.status.busy": "2024-12-07T01:44:51.494552Z",
     "iopub.status.idle": "2024-12-07T01:44:51.701908Z",
     "shell.execute_reply": "2024-12-07T01:44:51.700104Z",
     "shell.execute_reply.started": "2024-12-07T01:44:51.495371Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_tree(index_model, impurity=False, filled=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a very simple tree... what happened?"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1833,
     "sourceId": 3172,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
