{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribution: Kolhatkar, Varada (2024) DSCI572 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "import glob\n",
    "import json\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams.update({'axes.grid': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started with Kaggle Kernels\n",
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "91yxVPKkO2qa"
   },
   "source": [
    "We are going to run this notebook on the cloud using [Kaggle](https://www.kaggle.com). Kaggle offers 30 hours of free GPU usage per week which should be much more than enough for this lab. To get started, follow these steps:\n",
    "\n",
    "1. Go to https://www.kaggle.com/kernels\n",
    "\n",
    "2. Make an account if you don't have one, and verify your phone number (to get access to GPUs)\n",
    "3. Select `+ New Notebook`\n",
    "4. Go to `File -> Import Notebook`\n",
    "5. Upload this notebook\n",
    "6. On the right-hand side of your Kaggle notebook, make sure:\n",
    "  \n",
    "  - `Internet` is enabled.\n",
    "  \n",
    "  - In the `Accelerator` dropdown, choose `GPU` when you're ready to use it (you can turn it on/off as you need it).\n",
    "    \n",
    "7. Run the follow cells for preparation the model, labels and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Download ImageNet labels\n",
    "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def classify_image(img, topn = 4):\n",
    "    clf = models.vgg16(weights='VGG16_Weights.DEFAULT') # initialize the classifier with VGG16 weights\n",
    "    preprocess = transforms.Compose([\n",
    "                 transforms.Resize(299),\n",
    "                 transforms.CenterCrop(299),\n",
    "                 transforms.ToTensor(),\n",
    "                 transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                     std=[0.229, 0.224, 0.225]),])\n",
    "\n",
    "    with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "    img_t = preprocess(img)\n",
    "    batch_t = torch.unsqueeze(img_t, 0)\n",
    "    clf.eval()\n",
    "    output = clf(batch_t)\n",
    "    _, indices = torch.sort(output, descending=True)\n",
    "    probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "    d = {'Class': [classes[idx] for idx in indices[0][:topn]], \n",
    "         'Probability score': [np.round(probabilities[0, idx].item(),3) for idx in indices[0][:topn]]}\n",
    "    df = pd.DataFrame(d, columns = ['Class','Probability score'])\n",
    "    return df\n",
    "\n",
    "\n",
    "# Attribution: [Code from PyTorch docs](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html?highlight=transfer%20learning)\n",
    "IMAGE_SIZE = 200\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def read_data(data_dir, subdir):\n",
    "    \"\"\"\n",
    "    Reads image data from the specified directory and applies transformations.\n",
    "    \"\"\"\n",
    "    data_transforms = {\n",
    "        \"train\": transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),     \n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),            \n",
    "            ]\n",
    "        ),\n",
    "        \"valid\": transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),                        \n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),                        \n",
    "            ]\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    image_datasets = {\n",
    "        x: datasets.ImageFolder(os.path.join(data_dir, subdir[x]), data_transforms[x])\n",
    "        for x in [\"train\", \"valid\"]\n",
    "    }\n",
    "    \n",
    "    dataloaders = {}\n",
    "    \n",
    "    dataloaders[\"train\"] = torch.utils.data.DataLoader(\n",
    "            image_datasets[\"train\"], batch_size=BATCH_SIZE, shuffle=True\n",
    "        )\n",
    "    \n",
    "    dataloaders[\"valid\"] = torch.utils.data.DataLoader(\n",
    "            image_datasets[\"valid\"], batch_size=BATCH_SIZE, shuffle=True\n",
    "        )\n",
    "    \n",
    "    return image_datasets, dataloaders\n",
    "\n",
    "def get_features(model, data_loader, seed=None):\n",
    "    \"\"\"Extract output of squeezenet model\"\"\"\n",
    "    if seed:\n",
    "        torch.manual_seed(seed)\n",
    "    model.to(device)\n",
    "    with torch.no_grad():  # turn off computational graph stuff\n",
    "        Z_init = torch.empty((0, 1024)).to(device)  # Initialize empty tensors\n",
    "        y_init = torch.empty((0)).to(device)\n",
    "        for X, y in data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            Z_init = torch.cat((Z_init, model(X)), dim=0)\n",
    "            y_init = torch.cat((y_init, y))\n",
    "    return Z_init.cpu().detach(), y_init.cpu().detach()\n",
    "\n",
    "def show_predictions(pipe, Z_valid, y_valid, dataloader, class_names, num_images=20, seed=None):\n",
    "    \"\"\"Display images from the validation set and their predicted labels.\"\"\"\n",
    "    if seed:\n",
    "        torch.manual_seed(seed)\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure(figsize=(15, 25))  # Adjust the figure size for better visualization\n",
    "\n",
    "    # Convert the features and labels to numpy arrays\n",
    "    Z_valid = Z_valid.numpy()\n",
    "    y_valid = y_valid.numpy()\n",
    "\n",
    "    # Make predictions using the trained logistic regression model\n",
    "    preds = pipe.predict(Z_valid)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(dataloader):\n",
    "            inputs = inputs.cpu()\n",
    "            for j in range(inputs.size()[0]):\n",
    "                if images_so_far >= num_images:\n",
    "                    return\n",
    "                # print(f\"Dataloader Labels: {labels[j]}: {class_names['valid'][labels[j]]}\")\n",
    "                ax = plt.subplot(num_images // 5, 5, images_so_far + 1)  # 5 images per row\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f\"Predicted: {class_names['train'][int(preds[images_so_far])]}\"\n",
    "                             f\"\\nTrue: {class_names['valid'][int(y_valid[images_so_far])]}\")\n",
    "                inp = inputs.data[j].numpy().transpose((1, 2, 0))\n",
    "                mean = np.array([0.5, 0.5, 0.5])\n",
    "                std = np.array([0.5, 0.5, 0.5])\n",
    "                inp = std * inp + mean\n",
    "                inp = np.clip(inp, 0, 1)\n",
    "                ax.imshow(inp)\n",
    "                #imshow(inputs.data[j])\n",
    "                images_so_far += 1\n",
    "\n",
    "def show_image_label_prob(image_path, true_label, num_images):\n",
    "    \"\"\"\n",
    "    Displays a specified number of images from a given directory and prints their classification labels and probabilities.\n",
    "    \"\"\"\n",
    "    images = glob.glob(image_path)\n",
    "    selected_images = random.sample(images, num_images)\n",
    "    plt.figure(figsize=(5, 5));\n",
    "    for image in selected_images:\n",
    "        img = Image.open(image)\n",
    "        img.load()\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'Actual Label: {true_label}')\n",
    "        plt.show()\n",
    "        df = classify_image(img)    \n",
    "        print(df.to_string(index=False))\n",
    "        print(\"--------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've done all your work on Kaggle, you can download the notebook from Kaggle. That way any work you did on Kaggle won't be lost. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Transfer Learning\n",
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you're going to practice transfer learning. We're going to develop a model that can detect different fruits in this Kaggle [dataset](https://www.kaggle.com/datasets/karimabdulnabi/fruit-classification10-class):\n",
    "\n",
    "In order to use this dataset \n",
    "\n",
    "1. Click `+ Add data` at the top right of the notebook.\n",
    "\n",
    "2. Choose `Datasets`. In the search bar, type 'fruit-classification10-class'. You will see several datasets listed. Find and add the top dataset that has a size of 31 MB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-of-the-box Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BBefore starting the exercise, you will harness the power of a Convolutional Neural Network (CNN) model to classify images of cats and dogs using a common [dataset](https://www.kaggle.com/datasets/tongpython/cat-and-dog).\n",
    "\n",
    "However, training a CNN model from scratch can be computationally intensive. Therefore, you will use a pre-trained model (`VGG` for this case), to identify the animals efficiently!\n",
    "\n",
    "In order to use the dataset.\n",
    "\n",
    "1. Click `+ Add data` at the top right of the notebook.\n",
    "\n",
    "2. Choose `Datasets`. In the search bar, type 'cat-and-dog'. You will see several datasets listed. Find and add the top dataset that has a size of 228 MB.\n",
    "\n",
    "By running the following cell, you will obtain the image, the model's predictions (`Class`), and the associated probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set up data\n",
    "IMAGE_DIR = {\n",
    "    \"Cat\": \"/kaggle/input/cat-and-dog/test_set/test_set/cats/*.*\", \n",
    "    \"Dog\": \"/kaggle/input/cat-and-dog/test_set/test_set/dogs/*.*\"\n",
    "}\n",
    "\n",
    "# Display image and prediction labels with probability\n",
    "for true_label, image_path in IMAGE_DIR.items():\n",
    "    show_image_label_prob(image_path, true_label, num_images=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Food for Thought**: \n",
    "\n",
    "- How effectively can the model distinguish between cats and dogs?\n",
    "- Do you observe any particular characteristics about the labels?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to develop a model that can detect the following fruits in this Kaggle [dataset](https://www.kaggle.com/datasets/karimabdulnabi/fruit-classification10-class):\n",
    "\n",
    "- Apple\n",
    "- Banana\n",
    "- Avocado\n",
    "- Cherry\n",
    "- Kiwi\n",
    "- Mango\n",
    "- Orange\n",
    "- Pineapple\n",
    "- Strawberries\n",
    "- Watermelon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your tasks:**\n",
    "\n",
    "In this exercise, you will apply the pre-trained CNN model (`VGG` for this case) to classify images of fruits! \n",
    "\n",
    "To begin, you will need to obtain the image, the model's predictions (`Class`), and the associated probabilities by running the following cell.\n",
    "\n",
    "> If you encounter any error, please rerun the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set up data\n",
    "IMAGE_DIR = {\n",
    "    \"Apple\": \"/kaggle/input/fruit-classification10-class/MY_data/train/Apple/*.jpeg\", \n",
    "    \"Banana\": \"/kaggle/input/fruit-classification10-class/MY_data/train/Banana/*.jpeg\", \n",
    "    \"Avocado\": \"/kaggle/input/fruit-classification10-class/MY_data/train/avocado/*.jpeg\", \n",
    "    \"Cherry\": \"/kaggle/input/fruit-classification10-class/MY_data/train/cherry/*.jpeg\", \n",
    "    \"Kiwi\": \"/kaggle/input/fruit-classification10-class/MY_data/train/kiwi/*.jpeg\", \n",
    "    \"Mango\": \"/kaggle/input/fruit-classification10-class/MY_data/train/mango/*.jpeg\", \n",
    "    \"Orange\": \"/kaggle/input/fruit-classification10-class/MY_data/train/orange/*.jpeg\", \n",
    "    \"Pineapple\": \"/kaggle/input/fruit-classification10-class/MY_data/train/pinenapple/*.jpeg\", \n",
    "    \"Strawberries\": \"/kaggle/input/fruit-classification10-class/MY_data/train/strawberries/*.jpeg\", \n",
    "    \"Watermelon\": \"/kaggle/input/fruit-classification10-class/MY_data/train/watermelon/*.jpeg\", \n",
    "}\n",
    "\n",
    "# Display image and prediction labels with probability\n",
    "for true_label, image_path in IMAGE_DIR.items():\n",
    "    show_image_label_prob(image_path, true_label, num_images=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Food for Thought**: \n",
    "\n",
    "- How does the model perform on this dataset?\n",
    "- Do you think it does well in identifying each type of fruit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T01:31:04.573651Z",
     "iopub.status.busy": "2024-11-24T01:31:04.573302Z",
     "iopub.status.idle": "2024-11-24T01:31:04.578075Z",
     "shell.execute_reply": "2024-11-24T01:31:04.577044Z",
     "shell.execute_reply.started": "2024-11-24T01:31:04.573621Z"
    }
   },
   "source": [
    "### Feature Extractor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Your tasks:**\n",
    "\n",
    "In this exercise, you will utilize a pre-trained CNN model (`Densenet` for this case) , to extract features from images. Following this, you will train a machine learning classifier to identify different fruits!\n",
    "\n",
    "To get started, please run the following cell to prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set up data\n",
    "DATA_DIR = '/kaggle/input/fruit-classification10-class/MY_data/'\n",
    "SUBDIR = {'train': 'train', 'valid': 'test'}\n",
    "image_datasets, dataloaders = read_data(DATA_DIR, SUBDIR)\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"valid\"]}\n",
    "class_names = {\"train\": image_datasets[\"train\"].classes,\n",
    "               \"valid\": image_datasets[\"valid\"].classes}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you want to take a look at the images in training set, try this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot samples\n",
    "inputs, classes = next(iter(dataloaders[\"valid\"]))\n",
    "plt.figure(figsize=(10, 8)); \n",
    "plt.axis(\"off\"); \n",
    "plt.title(\"Sample valid Images\")\n",
    "plt.imshow(np.transpose(utils.make_grid(inputs, padding=1, normalize=True),(1, 2, 0)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, utilize the pre-trained model to extract features from the images by executing the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Download model and extract features\n",
    "model = models.densenet121(weights=\"DenseNet121_Weights.IMAGENET1K_V1\")\n",
    "model.classifier = nn.Identity()  # remove that last \"classification\" layer\n",
    "Z_train, y_train = get_features(\n",
    "    model, dataloaders[\"train\"], seed=42\n",
    ")\n",
    "Z_valid, y_valid = get_features(\n",
    "    model, dataloaders[\"valid\"], seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you want to take a look at the extracted features in training set, try this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(Z_train).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To proceed, you will use the extracted features and labels from the image to train a machine learning classifier (`LogisticRegression` for this case). Please run the cell below to begin the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {
     "tags": [
      "otter_ignore"
     ]
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train classification model\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression(max_iter=2000))\n",
    "pipe.fit(Z_train, y_train)\n",
    "print(\"Training score: \", pipe.score(Z_train, y_train))\n",
    "pipe.score(Z_valid, y_valid)\n",
    "print(\"Validation score: \", pipe.score(Z_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you want to take a look at the images in validation set and compare the actual labels with the predicted labels, try this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Show predictions for 25 images in the validation set (5 rows of 5 images)\n",
    "show_predictions(pipe, Z_valid, y_valid, dataloaders['valid'], class_names, num_images=25, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Food for Thought**: \n",
    "\n",
    "- How is the performance of the model?\n",
    "- How does the out-of-the-box model compare to the feature extractor model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Free Time (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your tasks**:\n",
    "\n",
    "Choose any image dataset that interests you and train a model using it!\n",
    "\n",
    "Feel free to discuss your ideas and progress with your teammates and the workshop team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"{_DATA_DIRECTORY_PATH_}\"\n",
    "SUBDIR = \"{_SUB_DIRECTORY_PATH_}\"\n",
    "# Example - dataset `cat-breed-mardhik`\n",
    "# DATA_DIR = '/kaggle/input/cat-breed/cat-breed/'\n",
    "# SUBDIR = {'train': 'TRAIN', 'valid': 'TEST'}\n",
    "\n",
    "# Set up data\n",
    "image_datasets, dataloaders = read_data(DATA_DIR, SUBDIR)\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"valid\"]}\n",
    "class_names = {\"train\": image_datasets[\"train\"].classes,\n",
    "               \"valid\": image_datasets[\"valid\"].classes}\n",
    "\n",
    "# Download model and extract features\n",
    "model = models.densenet121(weights=\"DenseNet121_Weights.IMAGENET1K_V1\")\n",
    "model.classifier = nn.Identity()  # remove that last \"classification\" layer\n",
    "Z_train, y_train = get_features(\n",
    "    model, dataloaders[\"train\"], seed=42\n",
    ")\n",
    "Z_valid, y_valid = get_features(\n",
    "    model, dataloaders[\"valid\"], seed=42\n",
    ")\n",
    "\n",
    "# Train classification model\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression(max_iter=2000))\n",
    "pipe.fit(Z_train, y_train)\n",
    "print(\"Training score: \", pipe.score(Z_train, y_train))\n",
    "pipe.score(Z_valid, y_valid)\n",
    "print(\"Validation score: \", pipe.score(Z_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot samples\n",
    "show_predictions(pipe, Z_valid, y_valid, dataloaders['valid'], class_names, num_images=25, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "lab4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 23777,
     "sourceId": 30378,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2529046,
     "sourceId": 4292212,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {}
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "f821000d0c0da66e5bcde88c37d59c8e0de03b40667fb62009a8148ca49465a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
