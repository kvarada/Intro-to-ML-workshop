{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSI-ML-workshop: Deep Learning and Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribution: Kolhatkar, Varada (2024) DSCI572 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms, utils, models\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from PIL import Image\n",
    "\n",
    "plt.rcParams.update({'axes.grid': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started with Kaggle Kernels\n",
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "91yxVPKkO2qa"
   },
   "source": [
    "We are going to run this notebook on the cloud using [Kaggle](https://www.kaggle.com). Kaggle offers 30 hours of free GPU usage per week which should be much more than enough for this lab. To get started, follow these steps:\n",
    "\n",
    "1. Go to https://www.kaggle.com/kernels\n",
    "\n",
    "2. Make an account if you don't have one, and verify your phone number (to get access to GPUs)\n",
    "3. Select `+ New Notebook`\n",
    "<img src=\"img/create_notebook.png\" alt=\"drawing\" width=\"500\"/>\n",
    "4. Go to `File -> Import Notebook`\n",
    "5. Upload this notebook\n",
    "6. On the right-hand side of your Kaggle notebook, make sure:\n",
    "  \n",
    "  - `Internet` is enabled.\n",
    "  \n",
    "  - In the `Accelerator` dropdown, choose `GPU` when you're ready to use it (you can turn it on/off as you need it).\n",
    "<img src=\"img/session_options.png\" alt=\"drawing\" width=\"300\"/>\n",
    "7. In Kaggle Notebook, running the follow cell should print out `\"Using device: cuda\"` which means a GPU is available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device.type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've done all your work on Kaggle, you can download the notebook from Kaggle. That way any work you did on Kaggle won't be lost. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Transfer Learning\n",
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you're going to practice transfer learning. We're going to develop a model that can detect the following 6 cat breeds in this Kaggle [dataset](https://www.kaggle.com/solothok/cat-breed):\n",
    "\n",
    "0. American Short hair\n",
    "1. Bengal\n",
    "2. Maine Soon\n",
    "3. Ragdoll\n",
    "4. Scottish Fold\n",
    "5. Sphinx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use this dataset \n",
    "\n",
    "1. Click `+ Add data` at the top right of the notebook.\n",
    "\n",
    "<img src=\"img/add_data1.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "2. Search for 'cat-breed-mardhik'. Several datasets will appear. Look for and 'Add' the dataset with the specific thumbnail below, which has a size of 93 MB.\n",
    "\n",
    "<img src=\"img/add_data2.png\" alt=\"drawing\" width=\"300\"/>\n",
    "<img src=\"img/cat-breed.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T01:31:04.573651Z",
     "iopub.status.busy": "2024-11-24T01:31:04.573302Z",
     "iopub.status.idle": "2024-11-24T01:31:04.578075Z",
     "shell.execute_reply": "2024-11-24T01:31:04.577044Z",
     "shell.execute_reply.started": "2024-11-24T01:31:04.573621Z"
    }
   },
   "source": [
    "### Feature Extractor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Your tasks:**\n",
    "\n",
    "In this exercise, you will build a CNN model to classify images of cats based on their breeds! \n",
    "\n",
    "However, training a CNN model from scratch requires a lot of computation resources. So, you will leverage a pre-trained model customized with your own layer(s) on top, to build a CNN classifier that can identify various cat breeds!\n",
    "\n",
    "First, run the follow cell for preparation of the data and model training setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data\n",
    "TRAIN_DIR = \"/kaggle/input/cat-breed/TRAIN/\"\n",
    "VALID_DIR = \"/kaggle/input/cat-breed/TEST/\"\n",
    "\n",
    "def data_loader(DIR):\n",
    "    IMAGE_SIZE = 200\n",
    "    BATCH_SIZE = 32\n",
    "    \n",
    "    data_transforms = transforms.Compose([\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    \n",
    "    dataset = datasets.ImageFolder(root=DIR, transform=data_transforms)\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    return loader\n",
    "\n",
    "train_loader = data_loader(TRAIN_DIR)\n",
    "valid_loader = data_loader(VALID_DIR)\n",
    "\n",
    "# Set up trainer\n",
    "def trainer(model, train_loader, valid_loader, epochs=20, verbose=True):\n",
    "    \"\"\"Simple training wrapper for PyTorch network.\"\"\"\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "    \n",
    "    train_loss, valid_loss, train_accuracy, valid_accuracy = [], [], [], []\n",
    "    for epoch in range(epochs):  # for each epoch\n",
    "        train_batch_loss = 0\n",
    "        train_batch_acc = 0\n",
    "        valid_batch_loss = 0\n",
    "        valid_batch_acc = 0\n",
    "        \n",
    "        # Training\n",
    "        model.train()\n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(X)\n",
    "            _, y_hat_labels = torch.softmax(y_hat, dim=1).topk(1, dim=1)\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_batch_loss += loss.item()\n",
    "            train_batch_acc += (y_hat_labels.squeeze() == y).type(torch.float32).mean().item()\n",
    "        train_loss.append(train_batch_loss / len(train_loader))\n",
    "        train_accuracy.append(train_batch_acc / len(train_loader))\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X, y in valid_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                y_hat = model(X)\n",
    "                _, y_hat_labels = torch.softmax(y_hat, dim=1).topk(1, dim=1)\n",
    "                loss = criterion(y_hat, y)\n",
    "                valid_batch_loss += loss.item()\n",
    "                valid_batch_acc += (y_hat_labels.squeeze() == y).type(torch.float32).mean().item()\n",
    "        valid_loss.append(valid_batch_loss / len(valid_loader))\n",
    "        valid_accuracy.append(valid_batch_acc / len(valid_loader))\n",
    "        \n",
    "        # Print progress\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch + 1}:\",\n",
    "                  f\"Train Loss: {train_loss[-1]:.3f}\",\n",
    "                  f\"Train Accuracy: {train_accuracy[-1]:.2f}\",\n",
    "                  f\"Valid Loss: {valid_loss[-1]:.3f}.\",\n",
    "                  f\"Valid Accuracy: {valid_accuracy[-1]:.2f}\")\n",
    "    \n",
    "    results = {\"train_loss\": train_loss,\n",
    "               \"train_accuracy\": train_accuracy,\n",
    "               \"valid_loss\": valid_loss,\n",
    "               \"valid_accuracy\": valid_accuracy}\n",
    "    return results\n",
    "\n",
    "def plot_samples(data_loader, model=None):\n",
    "    sample_batch = next(iter(data_loader))\n",
    "    plt.figure(figsize=(20, 16)); \n",
    "    plt.axis(\"off\"); \n",
    "    plt.title(\"Sample Images\")\n",
    "    plt.imshow(np.transpose(utils.make_grid(sample_batch[0], padding=1, normalize=True),(1, 2, 0)));\n",
    "    actual_labels = sample_batch[1].numpy()\n",
    "    print(f\"Actual Labels: {actual_labels}\")\n",
    "    if model:\n",
    "        _, y_hat_labels = torch.softmax(cnn_model(sample_batch[0].to(device)), dim=1).topk(1, dim=1)\n",
    "        predicted_labels = y_hat_labels.squeeze().cpu().numpy()\n",
    "        print(f\"Predicted labels: {predicted_labels}\")\n",
    "        print(f\"Accuracy: {np.mean(actual_labels == predicted_labels)}\")\n",
    "        \n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    ">If you want to take a look at the images after making a `train_loader`, try this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot samples\n",
    "plot_samples(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you will use any pre-trained model you wish (`DenseNet` for this case) and start training your model for 10 epochs by running the follow cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download model and freeze params\n",
    "cnn_model = models.densenet121(pretrained=True)\n",
    "for param in cnn_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Customize final classification layers\n",
    "new_layers = nn.Sequential(\n",
    "    nn.Linear(1024, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 6)\n",
    ")\n",
    "cnn_model.classifier = new_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {
     "tags": [
      "otter_ignore"
     ]
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Time to train\n",
    "epochs = 10\n",
    "results = trainer(cnn_model, train_loader, valid_loader, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you want to take a look at the images in validation set and compare the actual and the predicted labels, try this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot samples\n",
    "plot_samples(valid_loader, cnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Food for Thought**: \n",
    "\n",
    "- How is the performance of the model?\n",
    "- What do you think about the change in the model performance if you change the value of `epoch` and train the model again?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fine Tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Your tasks:**\n",
    "\n",
    "In this exercise, you will fine-tune your pre-trained model by updating more layers during training.\n",
    "\n",
    "You can fine-tune as many layers as you like: the whole model, or particular layers. Experiment with both modes of fine-tuning, and find which works better.\n",
    "\n",
    "You will start fine-tuning the last 2 layers of the model by running the follow cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {
     "tags": [
      "otter_ignore"
     ]
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download model and freeze params\n",
    "cnn_model = models.densenet121(pretrained=True)\n",
    "for param in cnn_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Customize final classification layers\n",
    "new_layers = nn.Sequential(\n",
    "    nn.Linear(1024, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 6)\n",
    ")\n",
    "cnn_model.classifier = new_layers\n",
    "\n",
    "print(f\"The number of layers in the model is {len(cnn_model.features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Customize number of fine-tuning layers\n",
    "num_fine_tuning_layer = 2\n",
    "if num_fine_tuning_layer > 0:\n",
    "    for layer in cnn_model.features[-num_fine_tuning_layer:]:\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Time to train\n",
    "epochs = 10\n",
    "results = trainer(cnn_model, train_loader, valid_loader, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you want to take a look at the images in validation set and compare the actual and the predicted labels, try this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot samples\n",
    "plot_samples(valid_loader, cnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Food for Thought**: \n",
    "\n",
    "- How is the performance of the model? Comment on the performance of this model compared to the \"feature extractor\" model.\n",
    "- What do you think about the change in the model performance if you change the value of `num_fine_tuning_layer` and train the model again? Do you notice any change in running time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Free Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your tasks**:\n",
    "\n",
    "You will add any labelled image dataset you like, use your own settings by changing the items with **{_ ... _}** and train your own model!\n",
    "\n",
    "Feel free to share your thoughts with your teammates and workshop team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"{_TRAIN_FILE_PATH_}\"\n",
    "VALID_DIR = \"{_VALID_FILE_PATH_}\"\n",
    "# Example\n",
    "# TRAIN_DIR = \"/kaggle/input/cat-breed/TRAIN/\"\n",
    "# VALID_DIR = \"/kaggle/input/cat-breed/TEST/\"\n",
    "\n",
    "train_loader = data_loader(TRAIN_DIR)\n",
    "valid_loader = data_loader(VALID_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot samples\n",
    "plot_samples(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init(num_label_classes, num_fine_tuning_layer):\n",
    "    # Download model and freeze params\n",
    "    model = models.densenet121(pretrained=True)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Customize final classification layers\n",
    "    new_layers = nn.Sequential(\n",
    "        nn.Linear(1024, 50),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(50, num_label_classes)\n",
    "    )\n",
    "    model.classifier = new_layers\n",
    "    \n",
    "    # Customize number of fine-tuning layers\n",
    "    if num_fine_tuning_layer > 0:\n",
    "        for layer in model.features[-num_fine_tuning_layer:]:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_label_classes = \"{_number_of_label_classes_in_the_dataset_}\"\n",
    "num_fine_tuning_layer = \"{_number_of_fine_tuning_layer_}\"\n",
    "epochs = \"{_epochs_}\"\n",
    "# Example\n",
    "# num_label_classes = 6\n",
    "# num_fine_tuning_layer = 1\n",
    "# epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to train\n",
    "cnn_model = model_init(num_label_classes, num_fine_tuning_layer)\n",
    "results = trainer(cnn_model, train_loader, valid_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot samples\n",
    "plot_samples(valid_loader, cnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/eva-congrats.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "lab4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1758005,
     "sourceId": 2870573,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {}
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "f821000d0c0da66e5bcde88c37d59c8e0de03b40667fb62009a8148ca49465a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
